// services/aiProvider.ts
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Universal AI Provider Abstraction Layer â€“ v2.0 (2026-02-14)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CHANGELOG:
// v2.0 â€“ FIX: Added dynamic max_tokens for OpenRouter based on
//         section key. Prevents 402 "insufficient credits" errors
//         by requesting only the tokens actually needed instead of
//         the model default (65536). Also improved 402 error handling
//         with user-friendly message.
// v1.0 â€“ Initial version.
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { GoogleGenAI, Type } from "@google/genai";
import { storageService } from './storageService.ts';
import { OPENROUTER_SYSTEM_PROMPT } from './Instructions.ts';

// â”€â”€â”€ TYPES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export type AIProviderType = 'gemini' | 'openrouter';

export interface AIProviderConfig {
  provider: AIProviderType;
  apiKey: string;
  model: string;
}

export interface AIGenerateOptions {
  prompt: string;
  jsonSchema?: any;
  jsonMode?: boolean;
  temperature?: number;
  sectionKey?: string;  // â˜… FIX v2.0: pass section key for dynamic max_tokens
}

export interface AIGenerateResult {
  text: string;
}

// â”€â”€â”€ â˜… FIX v2.0: DYNAMIC MAX_TOKENS PER SECTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// OpenRouter pre-charges credits for the FULL max_tokens budget.
// By right-sizing per section, we use 4â€“16Ã— fewer credits per call.
// These values are generous upper bounds â€“ actual output is usually 30-60% of this.

const SECTION_MAX_TOKENS: Record<string, number> = {
  // Large structured sections
  activities:          16384,  // Multiple WPs with tasks, milestones, deliverables
  expectedResults:     8192,   // Composite: outputs + outcomes + impacts
  
  // Medium sections
  projectManagement:   8192,   // Implementation + organigram description
  risks:               6144,   // Risk table with mitigations
  objectives:          6144,   // General + specific objectives
  
  // Smaller sections
  problemAnalysis:     4096,   // Core problem, causes, consequences
  projectIdea:         4096,   // Title, acronym, summary, state of the art
  outputs:             4096,
  outcomes:            4096,
  impacts:             4096,
  kers:                4096,   // Key Expected Results
  
  // Single field generation (used by generateFieldContent)
  field:               2048,
  
  // Summary & translation
  summary:             4096,
  translation:         8192,
};

const DEFAULT_MAX_TOKENS = 4096;

function getMaxTokensForSection(sectionKey?: string): number {
  if (!sectionKey) return DEFAULT_MAX_TOKENS;
  return SECTION_MAX_TOKENS[sectionKey] || DEFAULT_MAX_TOKENS;
}

// â”€â”€â”€ GEMINI MODELS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export const GEMINI_MODELS = [
  // â•â•â• GENERATION 3 (Latest) â•â•â•
  { id: 'gemini-3-pro-preview', name: 'Gemini 3 Pro (Preview)', description: 'Most intelligent â€” multimodal, agentic, reasoning' },
  { id: 'gemini-3-flash-preview', name: 'Gemini 3 Flash (Preview)', description: 'Balanced speed & intelligence' },

  // â•â•â• GENERATION 2.5 (Stable) â•â•â•
  { id: 'gemini-2.5-pro', name: 'Gemini 2.5 Pro', description: 'Advanced thinking â€” code, math, STEM, long context' },
  { id: 'gemini-2.5-flash', name: 'Gemini 2.5 Flash', description: 'Best price-performance â€” fast, thinking enabled' },
  { id: 'gemini-2.5-flash-lite', name: 'Gemini 2.5 Flash-Lite', description: 'Ultra fast â€” cost-efficient, high throughput' },

  // â•â•â• GENERATION 2.5 (Preview) â•â•â•
  { id: 'gemini-2.5-flash-preview-09-2025', name: 'Gemini 2.5 Flash Preview (Sep 2025)', description: 'Latest Flash preview with enhancements' },
  { id: 'gemini-2.5-flash-lite-preview-09-2025', name: 'Gemini 2.5 Flash-Lite Preview (Sep 2025)', description: 'Latest Flash-Lite preview' },

  // â•â•â• GENERATION 2.0 (Deprecated March 2026) â•â•â•
  { id: 'gemini-2.0-flash', name: 'Gemini 2.0 Flash (âš  deprecated)', description: 'Shutdown March 31, 2026 â€” migrate to 2.5+' },
  { id: 'gemini-2.0-flash-lite', name: 'Gemini 2.0 Flash-Lite (âš  deprecated)', description: 'Shutdown March 31, 2026 â€” migrate to 2.5+' },
];

// â”€â”€â”€ OPENROUTER POPULAR MODELS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export const OPENROUTER_MODELS = [
  // â•â•â• PROPRIETARY FLAGSHIP MODELS â•â•â•
  { id: 'openai/gpt-4o', name: 'OpenAI GPT-4o', description: 'Most capable OpenAI model' },
  { id: 'openai/gpt-4o-mini', name: 'OpenAI GPT-4o Mini', description: 'Fast & affordable OpenAI' },
  { id: 'openai/o3-mini', name: 'OpenAI o3-mini', description: 'OpenAI reasoning model' },
  { id: 'anthropic/claude-sonnet-4', name: 'Claude Sonnet 4', description: 'Anthropic balanced model' },
  { id: 'anthropic/claude-opus-4', name: 'Claude Opus 4', description: 'Anthropic most capable' },
  { id: 'google/gemini-2.5-pro-preview', name: 'Gemini 2.5 Pro (via OpenRouter)', description: 'Google via OpenRouter' },

  // â•â•â• OPEN-SOURCE â€” CHINESE FLAGSHIP ğŸ‡¨ğŸ‡³ â•â•â•
  { id: 'deepseek/deepseek-v3.2', name: 'ğŸ‡¨ğŸ‡³ DeepSeek V3.2', description: 'DeepSeek flagship â€“ top open-source, MoE 671B' },
  { id: 'deepseek/deepseek-r1', name: 'ğŸ‡¨ğŸ‡³ DeepSeek R1', description: 'DeepSeek reasoning model â€“ rivals OpenAI o1' },
  { id: 'deepseek/deepseek-r1-0528', name: 'ğŸ‡¨ğŸ‡³ DeepSeek R1 0528', description: 'Latest R1 update â€“ enhanced reasoning' },
  { id: 'moonshotai/kimi-k2.5', name: 'ğŸ‡¨ğŸ‡³ Kimi K2.5 (Moonshot AI)', description: '#1 open-source â€“ reasoning + visual coding' },
  { id: 'moonshotai/kimi-k2', name: 'ğŸ‡¨ğŸ‡³ Kimi K2 (Moonshot AI)', description: '1T param MoE â€“ coding & agentic tasks' },
  { id: 'z-ai/glm-5', name: 'ğŸ‡¨ğŸ‡³ GLM-5 (Zhipu AI)', description: 'Z.AI latest flagship â€“ frontier open-source' },
  { id: 'z-ai/glm-4.5-air:free', name: 'ğŸ‡¨ğŸ‡³ GLM-4.5 Air (FREE)', description: 'Zhipu AI â€“ free lightweight model' },
  { id: 'qwen/qwen3-235b-a22b', name: 'ğŸ‡¨ğŸ‡³ Qwen3 235B A22B (Alibaba)', description: 'Alibaba MoE 235B â€“ top reasoning & coding' },
  { id: 'qwen/qwen3-max', name: 'ğŸ‡¨ğŸ‡³ Qwen3 Max (Alibaba)', description: 'Alibaba cloud-hosted flagship' },
  { id: 'qwen/qwen3-coder', name: 'ğŸ‡¨ğŸ‡³ Qwen3 Coder (Alibaba)', description: 'Alibaba coding specialist â€“ 480B MoE' },
  { id: 'minimax/minimax-m2.1', name: 'ğŸ‡¨ğŸ‡³ MiniMax M2.1', description: 'MiniMax flagship â€“ coding & agents, efficient' },
  { id: 'minimax/minimax-m2', name: 'ğŸ‡¨ğŸ‡³ MiniMax M2', description: 'MiniMax â€“ compact high-performance model' },

  // â•â•â• OPEN-SOURCE â€” META LLAMA ğŸ¦™ â•â•â•
  { id: 'meta-llama/llama-4-maverick', name: 'ğŸ¦™ Llama 4 Maverick (Meta)', description: 'Meta MoE 128 experts â€“ top Llama model' },
  { id: 'meta-llama/llama-4-scout', name: 'ğŸ¦™ Llama 4 Scout (Meta)', description: 'Meta MoE 16 experts â€“ fast & efficient' },
  { id: 'meta-llama/llama-3.3-70b-instruct', name: 'ğŸ¦™ Llama 3.3 70B (Meta)', description: 'Meta proven workhorse â€“ great price/quality' },

  // â•â•â• OPEN-SOURCE â€” MISTRAL ğŸ‡«ğŸ‡· â•â•â•
  { id: 'mistralai/mistral-large-2512', name: 'ğŸ‡«ğŸ‡· Mistral Large 3 (Dec 2025)', description: 'Mistral flagship â€“ 262K context' },
  { id: 'mistralai/devstral-2512', name: 'ğŸ‡«ğŸ‡· Devstral 2 (Mistral)', description: 'Mistral agentic coding specialist â€“ 123B MoE' },
  { id: 'mistralai/mistral-small-2503', name: 'ğŸ‡«ğŸ‡· Mistral Small (Mar 2025)', description: 'Mistral lightweight â€“ fast responses' },
];

// â”€â”€â”€ PROVIDER DETECTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function getProviderConfig(): AIProviderConfig {
  const provider = storageService.getAIProvider() || 'gemini';
  const model = storageService.getCustomModel() || getDefaultModel(provider);

  let apiKey = '';
  if (provider === 'gemini') {
    apiKey = storageService.getApiKey() || '';
    if (!apiKey && typeof process !== 'undefined' && process.env?.API_KEY) {
      apiKey = process.env.API_KEY;
    }
  } else if (provider === 'openrouter') {
    apiKey = storageService.getOpenRouterKey() || '';
  }

  return { provider, apiKey, model };
}

export function getDefaultModel(provider: AIProviderType): string {
  if (provider === 'openrouter') return 'deepseek/deepseek-v3.2';
  return 'gemini-3-pro-preview';
}

// â”€â”€â”€ VALIDATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function validateProviderKey(provider: AIProviderType, apiKey: string): Promise<boolean> {
  if (!apiKey || apiKey.trim().length < 10) return false;

  try {
    if (provider === 'gemini') {
      if (!apiKey.startsWith('AIza') || apiKey.length < 35) return false;
      const client = new GoogleGenAI({ apiKey });
      await client.models.countTokens({
        model: 'gemini-3-flash-preview',
        contents: [{ parts: [{ text: "test" }] }]
      });
      return true;
    }

    if (provider === 'openrouter') {
      const response = await fetch('https://openrouter.ai/api/v1/models', {
        headers: { 'Authorization': `Bearer ${apiKey}` }
      });
      return response.ok;
    }

    return false;
  } catch (error) {
    console.error(`${provider} API Key Validation Failed:`, error);
    return false;
  }
}

export function hasValidProviderKey(): boolean {
  const config = getProviderConfig();
  if (config.provider === 'gemini') {
    return config.apiKey.startsWith('AIza') && config.apiKey.length >= 35;
  }
  if (config.provider === 'openrouter') {
    return config.apiKey.length > 10;
  }
  return false;
}

// â”€â”€â”€ GENERATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function generateContent(options: AIGenerateOptions): Promise<AIGenerateResult> {
  const config = getProviderConfig();

  if (!config.apiKey) {
    throw new Error('MISSING_API_KEY');
  }

  if (config.provider === 'gemini') {
    return generateWithGemini(config, options);
  }

  if (config.provider === 'openrouter') {
    return generateWithOpenRouter(config, options);
  }

  throw new Error(`Unknown AI provider: ${config.provider}`);
}

// â”€â”€â”€ GEMINI ADAPTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function generateWithGemini(config: AIProviderConfig, options: AIGenerateOptions): Promise<AIGenerateResult> {
  const client = new GoogleGenAI({ apiKey: config.apiKey });

  const generateConfig: any = {};
  if (options.jsonSchema) {
    generateConfig.responseMimeType = "application/json";
    generateConfig.responseSchema = options.jsonSchema;
  }
  if (options.temperature !== undefined) {
    generateConfig.temperature = options.temperature;
  }

  try {
    const response = await client.models.generateContent({
      model: config.model,
      contents: options.prompt,
      config: Object.keys(generateConfig).length > 0 ? generateConfig : undefined,
    });

    return { text: response.text.trim() };
  } catch (e: any) {
    handleProviderError(e, 'gemini');
    throw e;
  }
}

// â”€â”€â”€ OPENROUTER ADAPTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// â˜… FIX v2.0: Now includes dynamic max_tokens + 402 error handling

async function generateWithOpenRouter(config: AIProviderConfig, options: AIGenerateOptions): Promise<AIGenerateResult> {
  const messages: any[] = [
    { role: 'user', content: options.prompt }
  ];

    if (options.jsonSchema || options.jsonMode) {
    messages.unshift({
      role: 'system',
      content: OPENROUTER_SYSTEM_PROMPT
    });
  }

  // â˜… FIX v2.0: Calculate appropriate max_tokens for this section
  const maxTokens = getMaxTokensForSection(options.sectionKey);

  const body: any = {
    model: config.model,
    messages: messages,
    max_tokens: maxTokens,  // â˜… FIX v2.0: explicit limit instead of model default (65536)
  };

  if (options.jsonSchema || options.jsonMode) {
    body.response_format = { type: 'json_object' };
  }

  if (options.temperature !== undefined) {
    body.temperature = options.temperature;
  }

  try {
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${config.apiKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': window.location.origin,
        'X-Title': 'EU Intervention Logic AI Assistant'
      },
      body: JSON.stringify(body)
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      const errorMsg = errorData?.error?.message || `HTTP ${response.status}`;

      if (response.status === 401 || response.status === 403) {
        throw new Error('MISSING_API_KEY');
      }
      if (response.status === 429) {
        throw new Error('API Quota Exceeded. You have reached the rate limit. Please try again later or switch to a different model/plan.');
      }
      // â˜… FIX v2.0: Handle 402 (insufficient credits) with clear message
      if (response.status === 402) {
        throw new Error(`Insufficient OpenRouter credits. Requested ${maxTokens} max_tokens for "${options.sectionKey || 'unknown'}" section. Please add credits at https://openrouter.ai/settings/credits or switch to a free/cheaper model.`);
      }
      throw new Error(`OpenRouter Error: ${errorMsg}`);
    }

    const data = await response.json();
    const text = data.choices?.[0]?.message?.content?.trim() || '';

    if (!text) {
      throw new Error('OpenRouter returned empty response');
    }

    return { text };
  } catch (e: any) {
    if (e.message === 'MISSING_API_KEY' || e.message?.includes('Quota') || e.message?.includes('Insufficient OpenRouter')) {
      throw e;
    }
    handleProviderError(e, 'openrouter');
    throw e;
  }
}

// â”€â”€â”€ ERROR HANDLING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function handleProviderError(e: any, provider: string): never {
  const msg = e.message || e.toString();

  if (msg === 'MISSING_API_KEY' || msg.includes('400') || msg.includes('403') || msg.includes('API key not valid') || msg.includes('401')) {
    throw new Error('MISSING_API_KEY');
  }

  if (msg.includes('429') || msg.includes('quota') || msg.includes('RESOURCE_EXHAUSTED') || msg.includes('rate limit')) {
    throw new Error("API Quota Exceeded. You have reached the rate limit. Please try again later or switch to a different model/plan.");
  }

  // â˜… FIX v2.0: Pass through 402 / credits errors without wrapping
  if (msg.includes('402') || msg.includes('credits') || msg.includes('Insufficient')) {
    throw e;
  }

  console.error(`${provider} API Error:`, e);
  throw new Error(`AI Generation Failed (${provider}): ${msg.substring(0, 150)}...`);
}
